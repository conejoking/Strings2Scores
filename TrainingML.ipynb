{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_audio_features(wav_file_path, feature_type):\n",
    "    hop_length = 512\n",
    "    #Load Data\n",
    "    y, sr = librosa.load(wav_file_path, sr=None)  # Load the audio file\n",
    "\n",
    "    #Trim audio to remove silence \n",
    "    waveform_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
    "\n",
    "    # Normalize the audio waveform (optional)\n",
    "    waveform_normalized = librosa.util.normalize(waveform_trimmed)\n",
    "\n",
    "    if feature_type == \"mfcc\":\n",
    "        print(\"Extracting MFCCs...\")\n",
    "        features = librosa.feature.mfcc(y=waveform_normalized, sr=sr)\n",
    "    elif feature_type == \"const_Q\":\n",
    "        print(\"Extracting Constant-Q transform...\")\n",
    "        features = librosa.core.cqt(y=waveform_normalized, sr=sr)\n",
    "    elif feature_type == \"chroma\":\n",
    "        print(\"Extracting Chroma transform...\")\n",
    "        features = librosa.feature.chroma_stft(y=waveform_normalized, sr=sr)\n",
    "    elif feature_type == \"mel_spec\":\n",
    "        features = librosa.feature.melspectrogram(y=waveform_normalized, sr=sr, hop_length=hop_length)\n",
    "    elif feature_type == \"stft\":\n",
    "        features = librosa.stft(y=waveform_normalized) \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported feature type specified!\")\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_transform_audio_features(wav_file_path, feature_type):\n",
    "    hop_length = 512\n",
    "    #Load Data\n",
    "    y, sr = librosa.load(wav_file_path, sr=None)  # Load the audio file\n",
    "    \n",
    "    y = librosa.effects.pitch_shift(y=y, sr = sr, n_steps=random.randint(-5, 5)/100) # Perform pitch shifting\n",
    "\n",
    "    #Trim audio to remove silence \n",
    "    waveform_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
    "\n",
    "    # Normalize the audio waveform (optional)\n",
    "    waveform_normalized = librosa.util.normalize(waveform_trimmed)\n",
    "\n",
    "    if feature_type == \"mfcc\":\n",
    "        print(\"Extracting MFCCs...\")\n",
    "        features = librosa.feature.mfcc(y=waveform_normalized, sr=sr)\n",
    "    elif feature_type == \"const_Q\":\n",
    "        print(\"Extracting Constant-Q transform...\")\n",
    "        features = librosa.core.cqt(y=waveform_normalized, sr=sr)\n",
    "    elif feature_type == \"chroma\":\n",
    "        print(\"Extracting Chroma transform...\")\n",
    "        features = librosa.feature.chroma_stft(y=waveform_normalized, sr=sr)\n",
    "    elif feature_type == \"mel_spec\":\n",
    "        features = librosa.feature.melspectrogram(y=waveform_normalized, sr=sr, hop_length=hop_length)\n",
    "    elif feature_type == \"stft\":\n",
    "        features = librosa.stft(y=waveform_normalized) \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported feature type specified!\")\n",
    "    return features\n",
    "\n",
    "def extract_time_transform_audio_features(wav_file_path, feature_type):\n",
    "    hop_length = 512\n",
    "    #Load Data\n",
    "    y, sr = librosa.load(wav_file_path, sr=None)  # Load the audio file\n",
    "\n",
    "    y = librosa.effects.time_stretch(y=y, rate=1 + random.randint(-5, 5)/100)\n",
    "    \n",
    "\n",
    "    #Trim audio to remove silence \n",
    "    waveform_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
    "\n",
    "    # Normalize the audio waveform (optional)\n",
    "    waveform_normalized = librosa.util.normalize(waveform_trimmed)\n",
    "\n",
    "    if feature_type == \"mfcc\":\n",
    "        print(\"Extracting MFCCs...\")\n",
    "        features = librosa.feature.mfcc(y=waveform_normalized, sr=sr)\n",
    "    elif feature_type == \"const_Q\":\n",
    "        print(\"Extracting Constant-Q transform...\")\n",
    "        features = librosa.core.cqt(y=waveform_normalized, sr=sr)\n",
    "    elif feature_type == \"chroma\":\n",
    "        print(\"Extracting Chroma transform...\")\n",
    "        features = librosa.feature.chroma_stft(y=waveform_normalized, sr=sr)\n",
    "    elif feature_type == \"mel_spec\":\n",
    "        features = librosa.feature.melspectrogram(y=waveform_normalized, sr=sr, hop_length=hop_length)\n",
    "    elif feature_type == \"stft\":\n",
    "        features = librosa.stft(y=waveform_normalized) \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported feature type specified!\")\n",
    "    return features\n",
    "\n",
    "# Example usage:\n",
    "# Feature options: 'mfcc', 'const_Q', 'chroma', 'mel_spec'\n",
    "# features = extract_audio_features('twink.wav', 'mel_spec')\n",
    "# print(\"feature shape: \", features.shape)  # This should print the shape of the extracted MFCC feature matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1_Hot_encoding \n",
    "import numpy as np\n",
    "\n",
    "# Define vocabulary (example)\n",
    "vocabulary = ['\\n','c', 'd', 'e', 'f', 'g', 'a', 'b', 'i', '\\\\', '|', ' ', '\\'', 's', '2', '4', '8','k', 'y', 'm', 'j', 'o', 'r']  # Notes: C to B, Rest, Whole note\n",
    "\n",
    "# Create mapping from symbols to indices\n",
    "symbol_to_index = {symbol: i for i, symbol in enumerate(vocabulary)}\n",
    "\n",
    "\n",
    "\n",
    "def encode_lilypond_lines_one_hot(lines, symbol_to_index):\n",
    "    num_symbols = len(symbol_to_index)\n",
    "    encoded_matrices = []\n",
    "\n",
    "    total_length = sum(len(line) for line in lines)  # Total length of all lines combined\n",
    "    # Initialize a large matrix to hold the entire encoding\n",
    "    encoded_matrix = np.zeros((num_symbols, total_length))\n",
    "\n",
    "    current_position = 0\n",
    "    for line in lines:\n",
    "        # Encode each line\n",
    "        for char in line:\n",
    "            if char in symbol_to_index:\n",
    "                encoded_matrix[symbol_to_index[char], current_position] = 1\n",
    "            else:\n",
    "                print(f\"Warning: Character '{char}' not found in vocabulary.\")\n",
    "            current_position += 1\n",
    "\n",
    "    return encoded_matrix\n",
    "\n",
    "\n",
    "def read_lilypond_from_file(ly_file_path):\n",
    "    lilypond_notations = []\n",
    "    start_reading = False\n",
    "    key_signature = None\n",
    "    mode = None\n",
    "    with open(ly_file_path, 'r') as file:\n",
    "        notation = \"\"\n",
    "        for line in file:\n",
    "            if \"\\key\" in line:\n",
    "                start_reading = True\n",
    "                # Extract key signature and mode from the \\key line\n",
    "                # key_line = line.strip().split()\n",
    "                # key_signature = key_line[1]\n",
    "                # mode = key_line[2]\n",
    "            if start_reading:\n",
    "                for char in line:\n",
    "                    if char == '}':\n",
    "                        start_reading = False\n",
    "                        break  # Stop reading at '}'\n",
    "                    if char.isalpha() or char in ['\\n',\"'\", ',', '|', '\\\\', ' ', '/', '2', '4', '8']:  # Include apostrophe, comma, and vertical bar\n",
    "                        notation += char\n",
    "                if notation:\n",
    "                    lilypond_notations.append(notation)\n",
    "                    notation = \"\"\n",
    "    return lilypond_notations\n",
    "\n",
    "def pullLilypondData(ly_file_path):\n",
    "    lilypond_notations = read_lilypond_from_file(ly_file_path)\n",
    "    #print(lilypond_notations)\n",
    "    encoded_sequences = encode_lilypond_lines_one_hot(lilypond_notations, symbol_to_index)\n",
    "    #encoded_sequences_array = package_1_hot(encoded_sequences)\n",
    "    return encoded_sequences\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # # Example Lilypond notation file path\n",
    "# ly_file_path = 'Twinkle.ly'\n",
    "\n",
    "# # # # Read Lilypond notation from the file\n",
    "# encoded_sequences_array = pullLilypondData(ly_file_path)\n",
    "\n",
    "# # # print(\"test\")\n",
    "# # print(\"printed array: \", encoded_sequences_array)\n",
    "\n",
    "# # # # Print the shape of the resulting array\n",
    "# print(\"Shape of the encoded sequences array:\", encoded_sequences_array.shape)\n",
    "\n",
    "# # # Print the type of the resulting array\n",
    "# # print(\"Type of the encoded sequences array:\", type(encoded_sequences_array))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pad_features(mfcc_features, max_length):\n",
    "    # mfcc_features is the original feature array\n",
    "    # max_length is the maximum length that you've chosen based on your dataset\n",
    "    pad_width = max_length - mfcc_features.shape[1]\n",
    "    if pad_width > 0:\n",
    "        return np.pad(mfcc_features, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        return mfcc_features\n",
    "\n",
    "                                \n",
    "def pad_lily(lily_hot, max_length):\n",
    "    # mfcc_features is the original feature array\n",
    "    # max_length is the maximum length that you've chosen based on your dataset\n",
    "    pad_width = max_length - lily_hot.shape[1]\n",
    "    print(pad_width)\n",
    "    if pad_width > 0:\n",
    "        return np.pad(lily_hot, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        return lily_hot\n",
    "                                \n",
    "#padded_features = pad_features(melSpect_features, 1261)\n",
    "#padded_features2 = pad_features(melSpect_features_2, 1261)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datasets bundled: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import random \n",
    "\n",
    "# Your existing functions here (extract_audio_features, pad_features, pullLilypondData, etc.)\n",
    "\n",
    "\n",
    "def find_matching_wav_files(base_name, folder_path):\n",
    "    pattern = re.compile(re.escape(base_name) + r'(\\(\\d+\\))?\\.wav$')\n",
    "    matching_files = [f for f in os.listdir(folder_path) if pattern.match(f)]\n",
    "    print(matching_files)\n",
    "    return matching_files\n",
    "\n",
    "def bundle_data_for_ml(feature_type):\n",
    "    folder_path = os.getcwd()  # Get the current working directory\n",
    "    dataset = []\n",
    "    ly_files = [f for f in os.listdir(folder_path) if f.endswith('.ly')]\n",
    "\n",
    "    for i, ly_file in enumerate(ly_files):\n",
    "        base_name = ly_file.replace('.ly', '')\n",
    "        matching_wav_files = find_matching_wav_files(base_name, folder_path)\n",
    "\n",
    "        for wav_file in matching_wav_files:\n",
    "            wav_path = os.path.join(folder_path, wav_file)\n",
    "            audio_features = extract_audio_features(wav_path, feature_type)\n",
    "            print(audio_features.shape)\n",
    "            padded_features = pad_features(audio_features, 4000)\n",
    "            ly_features = pullLilypondData(ly_file)\n",
    "            padded_lily = pad_lily(ly_features, 250)\n",
    "            dataset.append((padded_features, padded_lily))\n",
    "\n",
    "            # #Append a copy of the data to Augment the dataset\n",
    "            for _ in range(9):\n",
    "                dataset.append((padded_features.copy(), padded_lily.copy()))\n",
    "            \n",
    "            # # Apply pitch shifting and add transformed data to the dataset\n",
    "            for _ in range(19):\n",
    "                audio_features_shifted = extract_transform_audio_features(wav_path, feature_type)\n",
    "                padded_features_shifted = pad_features(audio_features_shifted, 4000)\n",
    "                dataset.append((padded_features_shifted, padded_lily))\n",
    "\n",
    "            for _ in range(19):\n",
    "                audio_features_shifted = extract_time_transform_audio_features(wav_path, feature_type)\n",
    "                padded_features_shifted = pad_features(audio_features_shifted, 4000)\n",
    "                dataset.append((padded_features_shifted, padded_lily))\n",
    "\n",
    "\n",
    "\n",
    "            extract_time_transform_audio_features\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    random.shuffle(dataset)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Feature options: 'mfcc', 'const_Q', 'chroma', 'mel_spec', \"stft\"\n",
    "dataset = bundle_data_for_ml('mel_spec')\n",
    "print(f\"Total datasets bundled: {len(dataset)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__ShuffleDatasetV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} buffer_size must be greater than zero. [Op:ShuffleDatasetV3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[207], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m     35\u001b[0m buffer_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset) \u001b[38;5;66;03m# Shuffle the entire dataset\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m dataset2 \u001b[38;5;241m=\u001b[39m \u001b[43mdataset2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mbatch(batch_size)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Optionally, repeat the dataset indefinitely (for multiple epochs)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# dataset = dataset.repeat()\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Define the LSTM model\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_lstm_model\u001b[39m(input_shape, output_shape):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1531\u001b[0m, in \u001b[0;36mDatasetV2.shuffle\u001b[1;34m(self, buffer_size, seed, reshuffle_each_iteration, name)\u001b[0m\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshuffle\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1463\u001b[0m             buffer_size,\n\u001b[0;32m   1464\u001b[0m             seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1465\u001b[0m             reshuffle_each_iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1466\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1467\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Randomly shuffles the elements of this dataset.\u001b[39;00m\n\u001b[0;32m   1468\u001b[0m \n\u001b[0;32m   1469\u001b[0m \u001b[38;5;124;03m  This dataset fills a buffer with `buffer_size` elements, then randomly\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1531\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mShuffleDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreshuffle_each_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5016\u001b[0m, in \u001b[0;36mShuffleDataset.__init__\u001b[1;34m(self, input_dataset, buffer_size, seed, reshuffle_each_iteration, name)\u001b[0m\n\u001b[0;32m   5012\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m   5014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (tf2\u001b[38;5;241m.\u001b[39menabled() \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   5015\u001b[0m     (context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function())):\n\u001b[1;32m-> 5016\u001b[0m   variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mshuffle_dataset_v3(\n\u001b[0;32m   5017\u001b[0m       input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   5018\u001b[0m       buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_size,\n\u001b[0;32m   5019\u001b[0m       seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seed,\n\u001b[0;32m   5020\u001b[0m       seed2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seed2,\n\u001b[0;32m   5021\u001b[0m       seed_generator\u001b[38;5;241m=\u001b[39mgen_dataset_ops\u001b[38;5;241m.\u001b[39mdummy_seed_generator(),\n\u001b[0;32m   5022\u001b[0m       reshuffle_each_iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reshuffle_each_iteration,\n\u001b[0;32m   5023\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n\u001b[0;32m   5024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5025\u001b[0m   variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mshuffle_dataset(\n\u001b[0;32m   5026\u001b[0m       input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   5027\u001b[0m       buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5030\u001b[0m       reshuffle_each_iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reshuffle_each_iteration,\n\u001b[0;32m   5031\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:7344\u001b[0m, in \u001b[0;36mshuffle_dataset_v3\u001b[1;34m(input_dataset, buffer_size, seed, seed2, seed_generator, output_types, output_shapes, reshuffle_each_iteration, metadata, name)\u001b[0m\n\u001b[0;32m   7342\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   7343\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 7344\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7345\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   7346\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__ShuffleDatasetV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} buffer_size must be greater than zero. [Op:ShuffleDatasetV3]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, MaxPooling1D, Reshape, Dropout, BatchNormalization\n",
    "from keras.layers import Bidirectional\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import librosa\n",
    "\n",
    "# Your functions for audio feature extraction, Lilypond data processing, etc. here\n",
    "# Check if GPU is available\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"GPU is available\")\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "else:\n",
    "    print(\"GPU is not available\")\n",
    "# Load Lilypond data and corresponding audio features, augment the dataset, and bundle it for ML\n",
    "#dataset = bundle_data_for_ml('mel_spec', max_feature_length, max_label_length)\n",
    "# Define a generator function to yield data samples\n",
    "def data_generator():\n",
    "    for features, labels in dataset:\n",
    "        yield features.astype(np.float32), labels.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a TensorFlow dataset from the generator function\n",
    "dataset2 = tf.data.Dataset.from_generator(data_generator, output_types=(tf.float32, tf.float32))\n",
    "\n",
    "# Shuffle and batch the dataset\n",
    "batch_size = 8\n",
    "buffer_size = len(dataset) # Shuffle the entire dataset\n",
    "dataset2 = dataset2.shuffle(buffer_size).batch(batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# Optionally, repeat the dataset indefinitely (for multiple epochs)\n",
    "# dataset = dataset.repeat()\n",
    "\n",
    "# Define the LSTM model\n",
    "def create_lstm_model(input_shape, output_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=512, go_backwards=True, return_sequences=True, input_shape=input_shape, recurrent_initializer='glorot_uniform'))\n",
    "    #model.add(Dropout(0.25)) \n",
    "    #BatchNormalization() \n",
    "    #model.add(MaxPooling1D(pool_size=2)) \n",
    "    # model.add(LSTM(units=32,  return_sequences=True))\n",
    "    # model.add(Dropout(0.25))  \n",
    "    model.add(LSTM(units=512))\n",
    "    # model.add(Dropout(0.25))\n",
    "    model.add(Dense(units=np.prod(output_shape), activation='softmax'))  # Output units equal to the flattened output shape\n",
    "    model.add(Reshape(output_shape))  # Reshape output to match the desired shape\n",
    "    return model\n",
    "\n",
    "# Define input and output shapes\n",
    "input_shape = dataset[0][0].shape  # Shape of the feature array\n",
    "output_shape = dataset[0][1].shape  # Shape of the label array\n",
    "\n",
    "# Create the LSTM model\n",
    "model = create_lstm_model(input_shape, output_shape)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Train the model using the entire dataset\n",
    "epochs = 100  # Specify the number of epochs\n",
    "history = model.fit(dataset2, epochs=epochs)\n",
    "\n",
    "# Plot the loss per epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss per Epoch')\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model\n",
    "model_save_path = 'my_model.keras'\n",
    "model.save(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the array: (128, 4000)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
      "(1, 23, 250)\n",
      "[11 11 11 11  9 17  3 18 11  2 11  9 19  6 20 21 22  0 11 11 11 11 11 11\n",
      " 11 11  2 12 11 11  3 12 11  4  8 13 12 11  5 12 11 10 11 12 12 11  7 12\n",
      " 12 11  8 13 12 12 11  2 12 12 11 12 11 11 11 11 11 11 11 11 11  3 11 12\n",
      " 11  4  8 12 11 12 11  5 12 12 11  6 12 12 11 10 11  7 12 12 11  1  8 13\n",
      " 12 12 12 11  2 12 12 12 11  1  8 13 12 12 12 11 10  0 11 11 11 11 11 11\n",
      " 11 11  7 12 12 11  6 12 12 11  5 12 12 11  4  8 13 12 12 11 10 11  3 12\n",
      " 12 11  2 12 12 11  1  8 13 12 12 11  7 12 11 10  0 11 11 11 11 11 11 11\n",
      " 11  6 12 11  5 12 11  4  8 13 12 11  3 12 11 10 11  2 12 11 10  0 11 11\n",
      " 13 14 18 21 20  5  6  1 11  1  6 11  3  1  5  6  4  1 22 13 14 17  4  5\n",
      " 11  5 15 18  2 21 14 13 14 15 13 22 21 16 13 15 16  1 14 19  6 16 11  6\n",
      " 18 20 20  8 12 21  1 19 10  3]\n",
      "[[[1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  ...\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]\n",
      "  [1 1 1 ... 1 1 1]]]\n",
      "(1, 23, 250)\n"
     ]
    }
   ],
   "source": [
    "#Prediction \n",
    "from tensorflow.keras.models import load_model\n",
    "hop_length = 512\n",
    "model_path = 'C:/Users/jzcon/Documents/UT Austin/StatML_HW1/my_model.keras'\n",
    "\n",
    "model = load_model(model_path)\n",
    "\n",
    "\n",
    "#Load file into librosa\n",
    "y, sr = librosa.load('Twinkle.wav')\n",
    "\n",
    "\n",
    "#Trim audio to remove silence \n",
    "waveform_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
    "\n",
    "# Normalize the audio waveform (optional)\n",
    "waveform_normalized = librosa.util.normalize(waveform_trimmed)\n",
    "\n",
    "#pull mfcc feature\n",
    "#test_feature = librosa.feature.mfcc(y=waveform_normalized, sr=sr)\n",
    "test_feature = librosa.feature.melspectrogram(y=waveform_normalized, sr=sr, hop_length=hop_length)\n",
    "#test_feature = librosa.feature.chroma_stft(y=waveform_normalized, sr=sr)\n",
    "# Print the shape of the resulting array\n",
    "\n",
    "test_feature_p = pad_features(test_feature, 4000)\n",
    "print(\"Shape of the array:\", test_feature_p.shape)\n",
    "input_data = np.expand_dims(test_feature_p, axis=0)\n",
    "#mfcc = np.expand_dims(mfccs_features_2, axis=0) \n",
    "\n",
    "prediction = model.predict(input_data)\n",
    "#prediction_reshaped = prediction.reshape(-1, 3, 169, 23)\n",
    "print(prediction.shape)\n",
    "\n",
    "\n",
    "# # Thresholding to select max value\n",
    "# binary_prediction = np.zeros_like(prediction)\n",
    "\n",
    "max_indices = np.squeeze(np.argmax(prediction, axis=1), axis=0)\n",
    "print(max_indices)\n",
    "\n",
    "\n",
    "# # print(max_indices.shape)\n",
    "# for i, max_index in enumerate(max_indices):\n",
    "#     binary_prediction[0, i, max_index] = 1\n",
    "#     print(binary_prediction)\n",
    "# #binary_prediction[0,0, max_indices[0]] = 1\n",
    "# print(binary_prediction)\n",
    "# print(binary_prediction.shape)\n",
    "\n",
    "# Assuming prediction_reshaped is the output you need to threshold\\n\",\n",
    "threshold = 0.00000000000000001\n",
    "binary_prediction = (prediction > threshold).astype(int)\n",
    "print(binary_prediction)\n",
    "print(binary_prediction.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\score {\n",
      "  \\new Staff {\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def decode_one_hot_to_lilypond(encoded_matrix, vocabulary):\n",
    "    lilypond_notation = \"\"\n",
    "    # Iterate over each column in the encoded_matrix\n",
    "    for i in range(encoded_matrix.shape[1]):\n",
    "        # Find the index of the '1' in this column\n",
    "        index = np.argmax(encoded_matrix[:, i])\n",
    "        if index < len(vocabulary):\n",
    "            lilypond_notation += vocabulary[index]\n",
    "    return lilypond_notation\n",
    "\n",
    "# Assuming encoded_matrix is the output from the updated one-hot encoding function\n",
    "# Example call to the decoder\n",
    "\n",
    "decoded_lilypond_notation = decode_one_hot_to_lilypond(binary_prediction[0], vocabulary)\n",
    "\n",
    "# Wrapping the decoded notation in a basic Lilypond score wrapper\n",
    "lilypond_score = \"\\\\score {\\n  \\\\new Staff {\\n    \" + decoded_lilypond_notation + \"\\n  }\\n}\"\n",
    "print(lilypond_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \\key d \\major\n",
      "        d'  e' fis' g' | '' b'' is'' d'' '         e ' fi' ' g'' a'' | b'' cis''' d''' cis''' |\n",
      "        b'' a'' g'' fis'' | e'' d'' cis'' b' |\n",
      "        a' g' fis' e' | d' |\n",
      "  s2yojgac ca ecgafcrs2kfg g4ydo2s24sro8s48c2ma8 ayjji'ocm|e\n"
     ]
    }
   ],
   "source": [
    "indexes = [11, 11, 11, 11, 9, 17, 3, 18, 11, 1, 11, 9, 19, 6, 20, 21, 22, 0, 11, 11, 11, 11, 1, 12,\n",
    "           15, 11, 2, 12, 11, 3, 12, 11, 4, 12, 11, 10, 11, 5, 12, 11, 6, 12, 11, 7, 12, 11, 1, 12,\n",
    "           12, 11, 10, 0, 11, 11, 11, 11, 1, 12, 12, 11, 7, 12, 11, 6, 12, 11, 5, 12, 11, 10, 11, 4,\n",
    "           12, 11, 3, 12, 11, 2, 12, 11, 1, 12, 11, 10, 0, 11, 11, 0, 10, 2, 12, 17, 12, 1, 8, 14,\n",
    "           0, 1, 20, 14, 12, 11, 6, 12, 11, 22, 2, 5, 7, 2, 19, 5, 19, 9, 13, 0, 13, 4, 11, 0, 5, 3,\n",
    "           10, 16, 7, 16, 9, 11, 1, 22, 6, 8, 10, 18, 12, 18, 12, 5, 22, 19, 17, 11, 8, 5, 19, 14, 18,\n",
    "           1, 15, 11, 7, 16, 17, 9, 3, 8, 17, 9, 0, 17, 6, 0, 16, 10, 11, 14, 10, 10, 11, 9, 14, 20,\n",
    "           19, 22, 19, 9, 14, 21, 14, 7, 1, 14, 11, 14, 5, 10, 19, 20, 9, 0, 10, 4, 9, 19, 6, 0, 4, 17,\n",
    "           4, 6, 13, 3, 4, 11, 6, 4, 19, 16, 6, 4, 12, 2, 11, 6, 21, 19, 6, 11, 12, 17, 20, 21, 12, 10,\n",
    "           16, 6, 0, 16, 0, 20, 7, 22, 3, 19, 20, 14, 14, 6, 10, 9, 0, 3, 4, 7, 10, 22, 16, 6, 12, 6]\n",
    "\n",
    "vocabulary = ['\\n', 'c', 'd', 'e', 'f', 'g', 'a', 'b', 'i', '\\\\', '|', ' ', '\\'', 's', '2', '4', '8',\n",
    "              'k', 'y', 'm', 'j', 'o', 'r']\n",
    "\n",
    "decoded_string = ''.join([vocabulary[idx] for idx in max_indices])\n",
    "print(decoded_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
